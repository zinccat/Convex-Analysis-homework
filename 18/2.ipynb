{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frank-Wolfe Algorithm\n",
    "\n",
    "By ZincCat\n",
    "\n",
    "$\\min _{\\mathbf{x} \\in \\mathbb{R}^{N}}\\|\\mathbf{y}-\\mathbf{D} \\mathbf{x}\\|_{2}^{2}$\n",
    "\n",
    "s.t. $\\|\\mathbf{x}\\|_{?} \\leq 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 200\n",
    "n = 300\n",
    "np.random.seed(19890817)\n",
    "D = np.random.normal(10, 5, (p, n))\n",
    "y = np.random.normal(10, 5, p)\n",
    "x0 = np.random.rand(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.linalg.norm(y-D@x)**2\n",
    "def grad(x):\n",
    "    return 2*D.T@(D@x-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用scipy求值\n",
    "from scipy.optimize import minimize\n",
    "cons1 = ({'type': 'ineq', 'fun': lambda x: 1 - np.linalg.norm(x, 1)})\n",
    "res = minimize(f, x0, constraints=cons1, tol=1e-4, options={'maxiter': 1e4, 'disp': True})\n",
    "minValue = res.fun\n",
    "print(\"Scipy result:\", res.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用scipy求值\n",
    "from scipy.optimize import minimize\n",
    "cons2 = ({'type': 'ineq', 'fun': lambda x: 1 - np.linalg.norm(x, np.inf)})\n",
    "res = minimize(f, x0, constraints=cons2, tol=1e-10, options={'maxiter': 1e4, 'disp': True})\n",
    "minValue2 = res.fun\n",
    "print(\"Scipy result:\", res.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fw(f, x, grad, maxIter, mode, log):\n",
    "    xn = x.copy()\n",
    "    for i in range(maxIter):\n",
    "        value = f(xn)\n",
    "        print(i, \"th iteration, f(x)=\", value)\n",
    "        log.append(value)\n",
    "        gamma = 2/(i+2)\n",
    "        g = grad(xn)\n",
    "        if mode == 1:\n",
    "            d = np.argmax(np.abs(g))\n",
    "            xn = (1-gamma)*xn\n",
    "            xn[d] -= gamma * np.sign(g[d])\n",
    "        elif mode == 'inf':\n",
    "            d = -np.sign(g)\n",
    "            xn += gamma * (d-xn)\n",
    "    return xn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$l_\\infty$ constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "maxIter = 3000000\n",
    "linf = []\n",
    "x = fw(f, x0/2/np.linalg.norm(x0, np.inf), grad, maxIter, 'inf', linf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log(linf))\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('$\\ln (f(x_k)-f^*)$')\n",
    "plt.savefig('wolfeInf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$l_1$ constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "maxIter = 300000\n",
    "l1 = []\n",
    "x2 = fw(f, x0/2/np.linalg.norm(x0, 1), grad, maxIter, 1, l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log(l1-minValue))\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('$\\ln (f(x_k)-f^*)$')\n",
    "plt.savefig('wolfe1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "projected gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P1(x):\n",
    "    norm = np.linalg.norm(x, 1)\n",
    "    if norm > 1:\n",
    "        return x/norm\n",
    "    return x\n",
    "def Pinf(x):\n",
    "    t = np.minimum(x, np.ones(n))\n",
    "    return np.maximum(t, -np.ones(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linesearch_Armijo(f, x, g, d, alpha=0.4, beta=0.8):\n",
    "    # backtrack linesearch using Armijo rules\n",
    "    t = 10.0\n",
    "    value = f(x)\n",
    "    while f(x + t*d) > value + alpha*t*np.dot(g, d):\n",
    "        t *= beta\n",
    "    return t\n",
    "def projectedDescent(f, x, grad, proj):\n",
    "    # 投影梯度下降函数\n",
    "    # 输入函数f, 目前x取值, 梯度函数, 要投影到的矩阵A\n",
    "    # 输出下降后x取值, 步长t\n",
    "    xn = x.copy()\n",
    "    g = grad(xn)\n",
    "    grad_norm = np.linalg.norm(g, 2)\n",
    "    d = -g/grad_norm\n",
    "    t = linesearch_Armijo(f, xn, g, d)\n",
    "    xn += t*d\n",
    "    return proj(xn), t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# 绘图\n",
    "time1 = []  # 记录时间步, 用于绘图\n",
    "values1 = []  # 记录某一时间步下函数值, 用于绘图\n",
    "Plot = True  # 是否绘图, 请保证此时alpha, beta均为单一取值\n",
    "timestep = 0\n",
    "\n",
    "x = x0.copy() #满足约束的初值\n",
    "\n",
    "# 用于判定终止\n",
    "count = 0 \n",
    "eps = 1e-13\n",
    "oldvalue = f(x)\n",
    "maxIter = 200000  # 最大迭代次数\n",
    "\n",
    "while True:\n",
    "    value = f(x)\n",
    "    print(\"Iteration:\", timestep, \"Value\", value)\n",
    "    # 用函数值改变量作为终止条件\n",
    "    if abs(value - oldvalue) < eps:\n",
    "        count += 1\n",
    "    else:\n",
    "        count = 0\n",
    "    oldvalue = value\n",
    "    if Plot:\n",
    "        time1.append(timestep)\n",
    "        values1.append(value)\n",
    "    if timestep > maxIter or count >= 5:\n",
    "        break\n",
    "    x, t = projectedDescent(f, x, grad, Pinf)  # 此时使用无穷范数\n",
    "    timestep += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc8f3ea9badafe9fc0f1b4faa22fba7f18b6863e43b73e6df2a27536033ffddf"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('ml': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}